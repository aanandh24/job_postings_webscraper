{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4753d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://jobs.lever.co/gotit/ \t  Machine Learning Engineer / Scientist Burlingame , CAAIFull - time\n",
      "https://jobs.lever.co/gotit/ \t [REMOTE] - Machine Learning Internship Palo Alto , CAAIIntern \n",
      "https://jobs.lever.co/concurrency/ \t [REMOTE] - Data Scientist United States Data & AIFull - time \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 229\u001b[0m\n\u001b[1;32m    225\u001b[0m lever_scraper \u001b[38;5;241m=\u001b[39m LeverWebScraper()\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m#lever_sites = lever_scraper.get_lever_sites()\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m#for l in lever_sites:\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m#    print(l)\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m postings_map \u001b[38;5;241m=\u001b[39m \u001b[43mlever_scraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_postings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 151\u001b[0m, in \u001b[0;36mLeverWebScraper.get_postings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(current_url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     html_page \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1280\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1035\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[1;32m   1341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "class LeverWebScraper:\n",
    "    def __init__(self):\n",
    "        self.urls = None\n",
    "    \n",
    "    def extract_urls(self, text):\n",
    "        regex_pattern = r\"(https?://[jobs.lever.co][^\\s]+)\"\n",
    "        urls = re.findall(regex_pattern, text)\n",
    "        return urls\n",
    "\n",
    "    def remove_tags(self, html):\n",
    "        # parse html content\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        for data in soup(['style', 'script']):\n",
    "            data.decompose()\n",
    "\n",
    "        return ' '.join(soup.stripped_strings)\n",
    "    \n",
    "    def get_lever_sites(self):\n",
    "        lever_gsheet = \"https://docs.google.com/spreadsheets/d/18u2sKRKjKz9gwRyob0p9KmcyVC6NX8JaJhjOqsRmbKY/edit?usp=sharing\"\n",
    "        csv_url = lever_gsheet\n",
    "        res = requests.get(url=csv_url)\n",
    "        content = res.content#.decode('utf-8')\n",
    "\n",
    "        content = self.remove_tags(content)\n",
    "        #print(\"content\")\n",
    "        #print(content)\n",
    "        urls = self.extract_urls(content)\n",
    "        return urls\n",
    "    \n",
    "    def strip_tags(self, html):\n",
    "        s = MLStripper()\n",
    "        s.feed(html)\n",
    "        return s.get_data()\n",
    "    \n",
    "    \n",
    "    def clean_job_posting(self, posting):\n",
    "        text = self.strip_tags(posting)\n",
    "\n",
    "        # Add spaces between consecutive uppercase letters and lowercase letters\n",
    "        cleaned_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
    "\n",
    "        # Add spaces between consecutive letters and non-letters\n",
    "        cleaned_text = re.sub(r'([a-zA-Z])([^a-zA-Z])', r'\\1 \\2', cleaned_text)\n",
    "        cleaned_text = re.sub(r'([^a-zA-Z])([a-zA-Z])', r'\\1 \\2', cleaned_text)\n",
    "\n",
    "        # Remove any remaining multiple spaces\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "\n",
    "        cleaned_text = cleaned_text.replace(\"( \", \"\")\n",
    "        cleaned_text = cleaned_text.replace(\" )\", \"\")\n",
    "\n",
    "\n",
    "        if cleaned_text.startswith('Apply'):\n",
    "            cleaned_text = cleaned_text.replace('Apply', '')\n",
    "\n",
    "        if cleaned_text.endswith('Remote'):\n",
    "            cleaned_text = '[REMOTE] - ' + cleaned_text\n",
    "            cleaned_text = cleaned_text.replace('Remote', '')  \n",
    "        elif cleaned_text.endswith('On-site'):\n",
    "            cleaned_text = '[ON-SITE] - ' + cleaned_text\n",
    "            cleaned_text = cleaned_text.replace('On-site', '')            \n",
    "        elif cleaned_text.endswith('Hybrid'):\n",
    "            cleaned_text = '[HYBRID] - ' + cleaned_text\n",
    "            cleaned_text = cleaned_text.replace('Hybrid', '')\n",
    "\n",
    "        if \"Full - Time\" in cleaned_text:\n",
    "            cleaned_text = '[Full-Time]' + cleaned_text\n",
    "            cleaned_text = cleaned_text.replace(\"Full - Time\", \"\")\n",
    "        elif \"Part - time\" in cleaned_text:\n",
    "            cleaned_text = '[Part-Time]' + cleaned_text\n",
    "            cleaned_text = cleaned_text.replace(\"Part - time\", \"\")        \n",
    "\n",
    "        cleaned_text = cleaned_text.replace(\"  \", \" \")\n",
    "\n",
    "\n",
    "        return cleaned_text\n",
    "\n",
    "        all_postings = list()\n",
    "\n",
    "        map0 = {\n",
    "            'urls': [],\n",
    "            'descriptions': [],\n",
    "            'points': []\n",
    "        }\n",
    "\n",
    "    def get_postings(self):\n",
    "\n",
    "        all_postings = list()\n",
    "\n",
    "        map0 = {\n",
    "            'urls': [],\n",
    "            'descriptions': [],\n",
    "            'points': []\n",
    "        }\n",
    "        links = self.get_lever_sites()\n",
    "        links = [l + \"/\" if not l.endswith(\"/\") else l for l in links ]\n",
    "        links = [l for l in links if \".eu.\" not in l] # Not looking for work in Europe (yet)\n",
    "\n",
    "        links = list(set(links))\n",
    "\n",
    "        random.shuffle(links)\n",
    "        random.shuffle(links)\n",
    "        random.shuffle(links)\n",
    "\n",
    "        current_link_n = 1\n",
    "        n_links = len(links)\n",
    "\n",
    "        #if True:\n",
    "        #    for l in links:\n",
    "        #        print(l)\n",
    "        #    return\n",
    "\n",
    "        for current_url in links:\n",
    "            #print(\"Link {0}/{1}\".format(current_link_n, n_links))\n",
    "            current_link_n += 1\n",
    "\n",
    "            req = Request(current_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            try:\n",
    "                html_page = urlopen(req).read()\n",
    "            except HTTPError as e:\n",
    "                if e.code == 404:\n",
    "                    print(\"HTTP 404 error: Page not found\")\n",
    "                else:\n",
    "                    print(\"An HTTP error occurred:\", e)\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(html_page, 'html.parser')\n",
    "            postings = soup.find_all(\"div\", {\"class\": \"posting\"})\n",
    "            for posting in postings:\n",
    "\n",
    "                clean_posting = self.clean_job_posting(str(posting))\n",
    "                clean_posting = clean_posting.replace('Sr . ', 'Sr. ')\n",
    "                points = 0\n",
    "\n",
    "                if \"intern\" in clean_posting.lower():\n",
    "                    points += 2\n",
    "                if \"Data\" in clean_posting:\n",
    "                    points += 1\n",
    "                if \"Analyst\" in clean_posting:\n",
    "                    points += 0.5\n",
    "                if \"REMOTE\" in clean_posting:\n",
    "                    points += 1\n",
    "                if \"Business Analyst\" in clean_posting:\n",
    "                    points += 0.5\n",
    "                if \"Business Intelligence\" in clean_posting:\n",
    "                    points += 1\n",
    "                if \"Data Scientist\" in clean_posting:\n",
    "                    points += 1\n",
    "                if \"Machine Learning\" in clean_posting:\n",
    "                    points += 1          \n",
    "\n",
    "                skip_posting = False\n",
    "\n",
    "                data_keyword_prsent = \"data\" in clean_posting.lower()\n",
    "                science_keyword_prsent = \"science\" in clean_posting.lower() or \"scientist\" in clean_posting.lower()\n",
    "                data_science_referenced = data_keyword_prsent and science_keyword_prsent\n",
    "\n",
    "                machine_learning_referenced = \"machine\" in clean_posting.lower() and \"learning\" in clean_posting.lower()\n",
    "\n",
    "                data_analyst_referenced = \"data\" in clean_posting.lower() and \"analyst\" in clean_posting.lower()\n",
    "\n",
    "                onsite_keywords = [\"on - site\", \"onsite\"]\n",
    "                foreign_locations = [\"UKLondon\", \"vienna\", \"istanbul\", \"singapore\", \"philippines\", \"australia\", \"santiago\", \"mumbai\"]\n",
    "                foreign_locations += [\"berlin\", \"bengaluru\"]\n",
    "                senority_keywords = [\"head of\", \"senior\", \"sr\", \"director\", \"lead\"]\n",
    "                keywords_to_exclude = onsite_keywords + foreign_locations + senority_keywords\n",
    "\n",
    "                for w in keywords_to_exclude:\n",
    "                    if w in clean_posting.lower():\n",
    "                        skip_posting = True\n",
    "                        break\n",
    "\n",
    "\n",
    "                if not (data_science_referenced or machine_learning_referenced or data_analyst_referenced): #and intern_keyword_present\n",
    "                    skip_posting = True\n",
    "\n",
    "                if skip_posting:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                map0['urls'].append(current_url)\n",
    "                map0['descriptions'].append(clean_posting)\n",
    "                map0['points'].append(points)      \n",
    "                print(current_url, '\\t', clean_posting)\n",
    "\n",
    "\n",
    "                #if clean_posting.startswith('[REMOTE]'):\n",
    "\n",
    "            #print('-'*40)\n",
    "            time.sleep(1.0)\n",
    "        return map0\n",
    "\n",
    "lever_scraper = LeverWebScraper()\n",
    "#lever_sites = lever_scraper.get_lever_sites()\n",
    "#for l in lever_sites:\n",
    "#    print(l)\n",
    "postings_map = lever_scraper.get_postings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab506da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urls</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>https://jobs.lever.co/gotit/</td>\n",
       "      <td>[REMOTE] - Machine Learning Internship Palo Alto , CAAIIntern</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>https://jobs.lever.co/overbond/</td>\n",
       "      <td>[REMOTE] - Data Science Intern - May 2023 PEY / Co - op Canada Data Science Full - time</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>https://jobs.lever.co/dott/</td>\n",
       "      <td>[HYBRID] - Data Analyst intern Amsterdam Data – Data Internship</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://jobs.lever.co/smartadserver/</td>\n",
       "      <td>[HYBRID] - Data Analyst Intern - Analytics Lab Paris Analytics Internship</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist India Hyderabad Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist Krakow Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist Columbo Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist Dhaka Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist Kinshasa Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://jobs.lever.co/concurrency/</td>\n",
       "      <td>[REMOTE] - Data Scientist United States Data &amp; AIFull - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://jobs.lever.co/dreem/</td>\n",
       "      <td>[HYBRID] - Machine Learning Research Intern Paris , Î le - de - France , France e Software Engineering – Algorithms Internship</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>https://jobs.lever.co/hopper/</td>\n",
       "      <td>[REMOTE] - Product Data Scientist , Ranking - Homes  - USHomes – Data Science</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://jobs.lever.co/hopper/</td>\n",
       "      <td>[REMOTE] - Product Data Scientist , Ranking - Homes  - CANHomes – Data Science</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>https://jobs.lever.co/hopper/</td>\n",
       "      <td>[Full-Time][REMOTE] - Data Scientist - Pricing &amp; Analytics , Fintech - CANFintech – Data Science</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>https://jobs.lever.co/hopper/</td>\n",
       "      <td>[Full-Time][REMOTE] - Data Scientist - Pricing &amp; Analytics , Fintech - USFintech – Data Science</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>https://jobs.lever.co/alkymi/</td>\n",
       "      <td>[REMOTE] - Data Scientist Data Science Full - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>https://jobs.lever.co/finstek/</td>\n",
       "      <td>[REMOTE] - Business Analyst Reporting / Data Warehouse Full - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>https://jobs.lever.co/compasslexecon/</td>\n",
       "      <td>[HYBRID] - Data Science Intern London , United Kingdom Data Science – Data Science Fixed - term</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>https://jobs.lever.co/Catch/</td>\n",
       "      <td>[REMOTE] - Data Scientist US Product Full - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>https://jobs.lever.co/trueaccord/</td>\n",
       "      <td>[REMOTE] - Data Scientist II Technology , True ML – Data Science Full - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://jobs.lever.co/quantco-/</td>\n",
       "      <td>[Full-Time][HYBRID] - Data Scientist Causal Inference / Machine Learning Europe Data Science</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist Capetown Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>https://jobs.lever.co/clari/</td>\n",
       "      <td>[REMOTE] - Staff Machine Learning Engineer -  , San Francisco Bay Area Engineering – Data Science and Machine Learning Full Time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist Islamabad Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>https://jobs.lever.co/CarbonDirect/</td>\n",
       "      <td>[Full-Time][REMOTE] - Data Scientist San Francisco , Seattle , or remote Science</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://jobs.lever.co/cohere/</td>\n",
       "      <td>[HYBRID] - Machine Learning Intern / Co - op Fall 2023) Toronto , Palo Alto , San Francisco , London Tech – Internships Intern , Remote</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://jobs.lever.co/alltrails/</td>\n",
       "      <td>[REMOTE] - Data Engineer , Machine Learning San Francisco Engineering Full - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>https://jobs.lever.co/videahealth/</td>\n",
       "      <td>Artificial Intelligence / Data Science Internship Boston Engineering Full - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>https://jobs.lever.co/atlassian/</td>\n",
       "      <td>[REMOTE] - Principal Technical Data Scientist Mountain View , United States Analytics &amp; Data Science Full Time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://jobs.lever.co/entefy/</td>\n",
       "      <td>[REMOTE] - Data Scientist  Jobs at Entefy – Product Force Full Time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://jobs.lever.co/tokenmetrics/</td>\n",
       "      <td>[Full-Time][REMOTE] - Crypto Data Scientist S ã o Paulo Data Science Team</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>https://jobs.lever.co/overbond/</td>\n",
       "      <td>[REMOTE] - Data Scientist Canada Data Science Full - time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://jobs.lever.co/nielsen/</td>\n",
       "      <td>[REMOTE] - Data Scientist (01313) New York , NYTechnology – Data Science Full Time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>https://jobs.lever.co/redaptiveinc/</td>\n",
       "      <td>[REMOTE] - Data Scientist Anywhere in India Redaptive Services Private Limited – India Team Full Time</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://jobs.lever.co/nielsen/</td>\n",
       "      <td>[REMOTE] - Data Ingest Analyst MXMexico City , Mexico Content &amp; Editorial – Content &amp; Editorial Full Time</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>https://jobs.lever.co/stackadapt/</td>\n",
       "      <td>[Full-Time][REMOTE] - Data Analyst Canada Partnerships and Business Solutions – Partnerships &amp; Solutions - Inventory</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>https://jobs.lever.co/agiloft/</td>\n",
       "      <td>[REMOTE] - QA Analyst II India QA and Data Science – QAContract</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://jobs.lever.co/nielsen/</td>\n",
       "      <td>[HYBRID] - Data Scientist / Data Analyst Warsaw , Poland Technology – Data Science Full Time</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>https://jobs.lever.co/mactores/</td>\n",
       "      <td>[REMOTE] - AWS Data Engineer Associate Seattle , WAEngineering – Data Engineering and Data Science Full time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>https://jobs.lever.co/dnb/</td>\n",
       "      <td>[HYBRID] - Principal Data Scientist Jacksonville - Florida - United States Data &amp; Analytics Employee : Full Time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>https://jobs.lever.co/dnb/</td>\n",
       "      <td>[HYBRID] - Principal Data Scientist Florham Park - New Jersey - United States Data &amp; Analytics Employee : Full Time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>https://jobs.lever.co/dnb/</td>\n",
       "      <td>[HYBRID] - Principal Data Scientist Jacksonville - Florida - United States Data &amp; Analytics Employee : Full Time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>https://jobs.lever.co/dnb/</td>\n",
       "      <td>[HYBRID] - Principal , Data Scientist R -14455) Chennai - India Data &amp; Analytics Employee : Full Time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>https://jobs.lever.co/agiloft/</td>\n",
       "      <td>[REMOTE] - Data Science Developer III India QA and Data Science – Data Science Contract</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>https://jobs.lever.co/agiloft/</td>\n",
       "      <td>[REMOTE] - QA and Release Manager India QA and Data Science – QAContract</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>https://jobs.lever.co/agiloft/</td>\n",
       "      <td>[REMOTE] - QA Automation Engineer II India QA and Data Science – QAContract</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>https://jobs.lever.co/wandb/</td>\n",
       "      <td>[REMOTE] - Customer Support Engineer , Machine Learning - EMEA London Customer Success – Support Full - time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>https://jobs.lever.co/wandb/</td>\n",
       "      <td>[REMOTE] - Machine Learning Engineer , Customer Success San Francisco , California Customer Success – Success ML Engineer - Enterprise Full - time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>https://jobs.lever.co/wandb/</td>\n",
       "      <td>[REMOTE] - Machine Learning Engineer , Customer Success - German Speaking London Customer Success – Success ML Engineer - Enterprise Full - time</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>https://jobs.lever.co/agiloft/</td>\n",
       "      <td>[REMOTE] - Machine Learning Software Engineer II India Engineering – Software Engineering Contract</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     urls  \\\n",
       "53           https://jobs.lever.co/gotit/   \n",
       "95        https://jobs.lever.co/overbond/   \n",
       "51            https://jobs.lever.co/dott/   \n",
       "17   https://jobs.lever.co/smartadserver/   \n",
       "23    https://jobs.lever.co/tokenmetrics/   \n",
       "25    https://jobs.lever.co/tokenmetrics/   \n",
       "27    https://jobs.lever.co/tokenmetrics/   \n",
       "28    https://jobs.lever.co/tokenmetrics/   \n",
       "29    https://jobs.lever.co/tokenmetrics/   \n",
       "32     https://jobs.lever.co/concurrency/   \n",
       "33           https://jobs.lever.co/dreem/   \n",
       "72          https://jobs.lever.co/hopper/   \n",
       "71          https://jobs.lever.co/hopper/   \n",
       "70          https://jobs.lever.co/hopper/   \n",
       "69          https://jobs.lever.co/hopper/   \n",
       "67          https://jobs.lever.co/alkymi/   \n",
       "66         https://jobs.lever.co/finstek/   \n",
       "63  https://jobs.lever.co/compasslexecon/   \n",
       "62           https://jobs.lever.co/Catch/   \n",
       "61      https://jobs.lever.co/trueaccord/   \n",
       "48        https://jobs.lever.co/quantco-/   \n",
       "24    https://jobs.lever.co/tokenmetrics/   \n",
       "99           https://jobs.lever.co/clari/   \n",
       "22    https://jobs.lever.co/tokenmetrics/   \n",
       "79    https://jobs.lever.co/CarbonDirect/   \n",
       "2           https://jobs.lever.co/cohere/   \n",
       "4        https://jobs.lever.co/alltrails/   \n",
       "86     https://jobs.lever.co/videahealth/   \n",
       "84       https://jobs.lever.co/atlassian/   \n",
       "7           https://jobs.lever.co/entefy/   \n",
       "26    https://jobs.lever.co/tokenmetrics/   \n",
       "96        https://jobs.lever.co/overbond/   \n",
       "14         https://jobs.lever.co/nielsen/   \n",
       "97    https://jobs.lever.co/redaptiveinc/   \n",
       "9          https://jobs.lever.co/nielsen/   \n",
       "56      https://jobs.lever.co/stackadapt/   \n",
       "76         https://jobs.lever.co/agiloft/   \n",
       "15         https://jobs.lever.co/nielsen/   \n",
       "87        https://jobs.lever.co/mactores/   \n",
       "57             https://jobs.lever.co/dnb/   \n",
       "58             https://jobs.lever.co/dnb/   \n",
       "59             https://jobs.lever.co/dnb/   \n",
       "60             https://jobs.lever.co/dnb/   \n",
       "75         https://jobs.lever.co/agiloft/   \n",
       "77         https://jobs.lever.co/agiloft/   \n",
       "78         https://jobs.lever.co/agiloft/   \n",
       "83           https://jobs.lever.co/wandb/   \n",
       "82           https://jobs.lever.co/wandb/   \n",
       "81           https://jobs.lever.co/wandb/   \n",
       "74         https://jobs.lever.co/agiloft/   \n",
       "\n",
       "                                                                                                                                           descriptions  \\\n",
       "53                                                                                       [REMOTE] - Machine Learning Internship Palo Alto , CAAIIntern    \n",
       "95                                                             [REMOTE] - Data Science Intern - May 2023 PEY / Co - op Canada Data Science Full - time    \n",
       "51                                                                                     [HYBRID] - Data Analyst intern Amsterdam Data – Data Internship    \n",
       "17                                                                           [HYBRID] - Data Analyst Intern - Analytics Lab Paris Analytics Internship    \n",
       "23                                                                       [Full-Time][REMOTE] - Crypto Data Scientist India Hyderabad Data Science Team    \n",
       "25                                                                                [Full-Time][REMOTE] - Crypto Data Scientist Krakow Data Science Team    \n",
       "27                                                                               [Full-Time][REMOTE] - Crypto Data Scientist Columbo Data Science Team    \n",
       "28                                                                                 [Full-Time][REMOTE] - Crypto Data Scientist Dhaka Data Science Team    \n",
       "29                                                                              [Full-Time][REMOTE] - Crypto Data Scientist Kinshasa Data Science Team    \n",
       "32                                                                                        [REMOTE] - Data Scientist United States Data & AIFull - time    \n",
       "33                      [HYBRID] - Machine Learning Research Intern Paris , Î le - de - France , France e Software Engineering – Algorithms Internship    \n",
       "72                                                                       [REMOTE] - Product Data Scientist , Ranking - Homes  - USHomes – Data Science    \n",
       "71                                                                      [REMOTE] - Product Data Scientist , Ranking - Homes  - CANHomes – Data Science    \n",
       "70                                                    [Full-Time][REMOTE] - Data Scientist - Pricing & Analytics , Fintech - CANFintech – Data Science    \n",
       "69                                                     [Full-Time][REMOTE] - Data Scientist - Pricing & Analytics , Fintech - USFintech – Data Science    \n",
       "67                                                                                                  [REMOTE] - Data Scientist Data Science Full - time    \n",
       "66                                                                                  [REMOTE] - Business Analyst Reporting / Data Warehouse Full - time    \n",
       "63                                                     [HYBRID] - Data Science Intern London , United Kingdom Data Science – Data Science Fixed - term    \n",
       "62                                                                                                    [REMOTE] - Data Scientist US Product Full - time    \n",
       "61                                                                        [REMOTE] - Data Scientist II Technology , True ML – Data Science Full - time    \n",
       "48                                                        [Full-Time][HYBRID] - Data Scientist Causal Inference / Machine Learning Europe Data Science    \n",
       "24                                                                              [Full-Time][REMOTE] - Crypto Data Scientist Capetown Data Science Team    \n",
       "99                    [REMOTE] - Staff Machine Learning Engineer -  , San Francisco Bay Area Engineering – Data Science and Machine Learning Full Time    \n",
       "22                                                                             [Full-Time][REMOTE] - Crypto Data Scientist Islamabad Data Science Team    \n",
       "79                                                                    [Full-Time][REMOTE] - Data Scientist San Francisco , Seattle , or remote Science    \n",
       "2              [HYBRID] - Machine Learning Intern / Co - op Fall 2023) Toronto , Palo Alto , San Francisco , London Tech – Internships Intern , Remote    \n",
       "4                                                                    [REMOTE] - Data Engineer , Machine Learning San Francisco Engineering Full - time    \n",
       "86                                                                     Artificial Intelligence / Data Science Internship Boston Engineering Full - time   \n",
       "84                                      [REMOTE] - Principal Technical Data Scientist Mountain View , United States Analytics & Data Science Full Time    \n",
       "7                                                                                  [REMOTE] - Data Scientist  Jobs at Entefy – Product Force Full Time    \n",
       "26                                                                           [Full-Time][REMOTE] - Crypto Data Scientist S ã o Paulo Data Science Team    \n",
       "96                                                                                           [REMOTE] - Data Scientist Canada Data Science Full - time    \n",
       "14                                                                  [REMOTE] - Data Scientist (01313) New York , NYTechnology – Data Science Full Time    \n",
       "97                                               [REMOTE] - Data Scientist Anywhere in India Redaptive Services Private Limited – India Team Full Time    \n",
       "9                                            [REMOTE] - Data Ingest Analyst MXMexico City , Mexico Content & Editorial – Content & Editorial Full Time    \n",
       "56                                [Full-Time][REMOTE] - Data Analyst Canada Partnerships and Business Solutions – Partnerships & Solutions - Inventory    \n",
       "76                                                                                     [REMOTE] - QA Analyst II India QA and Data Science – QAContract    \n",
       "15                                                        [HYBRID] - Data Scientist / Data Analyst Warsaw , Poland Technology – Data Science Full Time    \n",
       "87                                        [REMOTE] - AWS Data Engineer Associate Seattle , WAEngineering – Data Engineering and Data Science Full time    \n",
       "57                                    [HYBRID] - Principal Data Scientist Jacksonville - Florida - United States Data & Analytics Employee : Full Time    \n",
       "58                                 [HYBRID] - Principal Data Scientist Florham Park - New Jersey - United States Data & Analytics Employee : Full Time    \n",
       "59                                    [HYBRID] - Principal Data Scientist Jacksonville - Florida - United States Data & Analytics Employee : Full Time    \n",
       "60                                               [HYBRID] - Principal , Data Scientist R -14455) Chennai - India Data & Analytics Employee : Full Time    \n",
       "75                                                             [REMOTE] - Data Science Developer III India QA and Data Science – Data Science Contract    \n",
       "77                                                                            [REMOTE] - QA and Release Manager India QA and Data Science – QAContract    \n",
       "78                                                                         [REMOTE] - QA Automation Engineer II India QA and Data Science – QAContract    \n",
       "83                                        [REMOTE] - Customer Support Engineer , Machine Learning - EMEA London Customer Success – Support Full - time    \n",
       "82  [REMOTE] - Machine Learning Engineer , Customer Success San Francisco , California Customer Success – Success ML Engineer - Enterprise Full - time    \n",
       "81    [REMOTE] - Machine Learning Engineer , Customer Success - German Speaking London Customer Success – Success ML Engineer - Enterprise Full - time    \n",
       "74                                                  [REMOTE] - Machine Learning Software Engineer II India Engineering – Software Engineering Contract    \n",
       "\n",
       "    points  \n",
       "53     4.0  \n",
       "95     4.0  \n",
       "51     3.5  \n",
       "17     3.5  \n",
       "23     3.0  \n",
       "25     3.0  \n",
       "27     3.0  \n",
       "28     3.0  \n",
       "29     3.0  \n",
       "32     3.0  \n",
       "33     3.0  \n",
       "72     3.0  \n",
       "71     3.0  \n",
       "70     3.0  \n",
       "69     3.0  \n",
       "67     3.0  \n",
       "66     3.0  \n",
       "63     3.0  \n",
       "62     3.0  \n",
       "61     3.0  \n",
       "48     3.0  \n",
       "24     3.0  \n",
       "99     3.0  \n",
       "22     3.0  \n",
       "79     3.0  \n",
       "2      3.0  \n",
       "4      3.0  \n",
       "86     3.0  \n",
       "84     3.0  \n",
       "7      3.0  \n",
       "26     3.0  \n",
       "96     3.0  \n",
       "14     3.0  \n",
       "97     3.0  \n",
       "9      2.5  \n",
       "56     2.5  \n",
       "76     2.5  \n",
       "15     2.5  \n",
       "87     2.0  \n",
       "57     2.0  \n",
       "58     2.0  \n",
       "59     2.0  \n",
       "60     2.0  \n",
       "75     2.0  \n",
       "77     2.0  \n",
       "78     2.0  \n",
       "83     2.0  \n",
       "82     2.0  \n",
       "81     2.0  \n",
       "74     2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "df = pd.DataFrame(postings_map)\n",
    "df = df.sort_values(by=['points'], ascending=False)\n",
    "\n",
    "from pandas import option_context\n",
    "\n",
    "with option_context('display.max_colwidth', 400):\n",
    "    display(df.head(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
